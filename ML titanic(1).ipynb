{"cells":[{"cell_type":"code","source":["import pandas as pd\ntrain_df = sqlContext.read.load('/FileStore/tables/train.csv', \n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n\n\n\ntest_df=sqlContext.read.load('/FileStore/tables/test.csv', \n                          format='com.databricks.spark.csv', \n                          header='true', \n                          inferSchema='true')\n\n#pd.DataFrame(train_df.take(3), columns = census_data.columns)\n\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["train_df.show(2)\ntest_df.show(2)"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["## Add Survived column to test\nfrom pyspark.sql.functions import lit, col\ntrain_df = train_df.withColumn('Type',lit('train'))\n\ntrain_df.show(3)\n\ntest_df = (test_df.withColumn('Survived',lit(0))\n                  .withColumn('Type',lit('test')))\ntest_df.show(3)\n\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["test_df = test_df[train_df.columns]\ntest_df.show(3)\n# Append Test data to Train data\ndf = train_df.unionAll(test_df)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["df.show(3)\ndf = (df.withColumn('Age',df['Age'].cast('float'))\n            .withColumn('SibSp',df['SibSp'].cast('float'))\n            .withColumn('Parch',df['Parch'].cast('float'))\n            .withColumn('Fare',df['Fare'].cast('float'))\n            .withColumn('Survived',df['Survived'].cast('float'))\n            )\ndf.printSchema()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#Impute missing Age and Fare with the Average\n\ndef nullCount(df,var):\n    return df.filter(df[var].isNull()).count()\n  \nnumVars = ['Survived','Age','SibSp','Parch','Fare'] \nmissing = {var: nullCount(df,var) for var in numVars}\nage_mean = df.groupBy().mean('Age').first()[0]\nfare_mean = df.groupBy().mean('Fare').first()[0]\ndf = df.na.fill({'Age':age_mean,'Fare':fare_mean})\ndf.show(5)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType\nsplitFname = udf(lambda name: name.split(',')[1].split('.')[0],StringType())\ndf = df.withColumn('Title',splitFname(df['Name']))\ndf.show(3)\n\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["###One-Hot Encoding\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumns = [\"Sex\", \"Pclass\",\"Title\"]\nstages = [] # stages in our Pipeline\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Convert label into label indices using the StringIndexer\nlabel_stringIdx = StringIndexer(inputCol = \"Survived\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Transform all features into a vector using VectorAssembler\nnumericCols = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["import pandas as pd\ncols = df.columns\n# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(df)\ndataset = pipelineModel.transform(df)\n\n# Keep relevant columns\nselectedcols = [\"label\",\"features\"] + cols\ndataset = dataset.select(selectedcols)\ndataset.show(3)\n#display(dataset)\n#type(dataset)\ndataset.toPandas()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#split back train/test data\ntrain = dataset.filter(df.Type =='train')\ntest = dataset.filter(df.Type =='test')"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["### Randomly split data into training and test sets. set seed for reproducibility\n(trainingData, testData) = train.randomSplit([0.65, 0.35], seed = 110)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# Make predictions on test data using the transform() method.\n# LogisticRegression.transform() will only use the 'features' column.\npredictions = lrModel.transform(testData)\npredictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())\n\n# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\n\npredictions = cvModel.transform(testData)\n# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\n# Train model with Training Data\ndtModel = dt.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["print \"numNodes = \", dtModel.numNodes\nprint \"depth = \", dtModel.depth\n\n# Make predictions on test data using the Transformer.transform() method.\npredictions = dtModel.transform(testData)\n\npredictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)\n\ndt.getImpurity()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1,2,6,10])\n             .addGrid(dt.maxBins, [20,40,80])\n             .build())"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)\n# Takes ~5 minutes\n\nprint \"numNodes = \", cvModel.bestModel.numNodes\nprint \"depth = \", cvModel.bestModel.depth"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)\n\n# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)\n"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = rfModel.transform(testData)\n\npredictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)\n\n# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["from pyspark.ml.classification import MultilayerPerceptronClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n\n# specify layers for the neural network:\n# input layer of size 4 (features), two intermediate of size 5 and 4\n# and output of size 3 (classes)\nlayers = [24, 5, 4, 2]\n\n# create the trainer and set its parameters\nmp = MultilayerPerceptronClassifier(layers=layers)\n\n# Train model with Training Data\nmpModel = mp.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = mpModel.transform(testData)\npredictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["#from pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(mp.maxIter, [100,200])\n             .addGrid(mp.blockSize, [128, 256])\n             .addGrid(mp.seed, [1234])\n             .build())"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=mp, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)\n\n# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":41}],"metadata":{"name":"ML titanic","notebookId":1156122210405976},"nbformat":4,"nbformat_minor":0}
